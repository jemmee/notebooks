{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99535ed-83a6-4acb-bb2c-91c9d5604a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da79701b-44fb-4907-87b8-0720b54ce596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.11.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/lib/python3.13/site-packages (from tiktoken) (2025.7.34)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/anaconda3/lib/python3.13/site-packages (from tiktoken) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (2025.8.3)\n",
      "Downloading tiktoken-0.11.0-cp313-cp313-macosx_11_0_arm64.whl (997 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m997.1/997.1 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Installing collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7a67d1b-542f-4e92-bfe7-90059bd268b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: 'Hello, world! How are you?'\n",
      "------------------------------\n",
      "Encoded token IDs: [13225, 11, 2375, 0, 3253, 553, 481, 30]\n",
      "Number of tokens: 8\n",
      "Decoded tokens: ['Hello', ',', ' world', '!', ' How', ' are', ' you', '?']\n",
      "------------------------------\n",
      "Decoded text: 'Hello, world! How are you?'\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "# 1. Get the tokenizer for a specific model.\n",
    "# \"cl100k_base\" is the encoding used by GPT-4, GPT-3.5-Turbo, and others.\n",
    "#encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "encoding = tiktoken.get_encoding(\"o200k_base\")\n",
    "\n",
    "# 2. Define a sample string to encode and decode.\n",
    "text = \"Hello, world! How are you?\"\n",
    "#text = \"listen labs .ai /p uzzle\"\n",
    "\n",
    "print(f\"Original text: '{text}'\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 3. Encode the string into a list of token IDs.\n",
    "# The `encode()` method converts text into a sequence of integers (tokens).\n",
    "token_ids = encoding.encode(text)\n",
    "\n",
    "print(f\"Encoded token IDs: {token_ids}\")\n",
    "print(f\"Number of tokens: {len(token_ids)}\")\n",
    "\n",
    "# The tokenizer might break words into multiple tokens (e.g., \"Hello,\" becomes two tokens).\n",
    "decoded_tokens = [encoding.decode_single_token_bytes(token).decode('utf-8', errors='replace') for token in token_ids]\n",
    "print(f\"Decoded tokens: {decoded_tokens}\")\n",
    "\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 4. Decode the list of token IDs back into a string.\n",
    "# The `decode()` method is the inverse of `encode()`.\n",
    "decoded_text = encoding.decode(token_ids)\n",
    "\n",
    "print(f\"Decoded text: '{decoded_text}'\")\n",
    "\n",
    "# The original text and the decoded text should be identical.\n",
    "assert text == decoded_text\n",
    "\n",
    "print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54a9bdfb-0e68-478f-8b78-31b06e6a7d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter text to tokenize (or type 'quit' to exit):  Let there be light\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Text: 'Let there be light'\n",
      "Token IDs: [12845, 1354, 413, 4207]\n",
      "Number of tokens: 4\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter text to tokenize (or type 'quit' to exit):  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "# Encode text to token\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "# 1. First, make sure you have the tiktoken library installed:\n",
    "#    pip install tiktoken\n",
    "\n",
    "# 2. Get the tokenizer for a specific model.\n",
    "#    'cl100k_base' is the encoding used by GPT-4 and GPT-3.5-Turbo.\n",
    "#encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "encoding = tiktoken.get_encoding(\"o200k_base\")\n",
    "\n",
    "# 3. Start a loop to repeatedly prompt the user for text.\n",
    "while True:\n",
    "    print(\"-\" * 40)\n",
    "    user_input = input(\"Enter text to tokenize (or type 'quit' to exit): \")\n",
    "    \n",
    "    # 4. Check for the exit command.\n",
    "    if user_input.lower() in ['quit', 'exit']:\n",
    "        print(\"Exiting...\")\n",
    "        break\n",
    "    \n",
    "    # 5. Encode the user's input into tokens.\n",
    "    tokens = encoding.encode(user_input)\n",
    "    \n",
    "    # 6. Print the results.\n",
    "    print(f\"\\nOriginal Text: '{user_input}'\")\n",
    "    print(f\"Token IDs: {tokens}\")\n",
    "    print(f\"Number of tokens: {len(tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea18e90f-4cba-4af4-ad73-091f6f562e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a token ID (e.g., 24912) to decode, or type 'quit' to exit:  24912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Token ID: 24912\n",
      "Decoded Text: 'hello'\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a token ID (e.g., 24912) to decode, or type 'quit' to exit:  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "# Decode token to text\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "# Get the tokenizer for the model.\n",
    "# 'cl100k_base' is the encoding used by GPT-4 and GPT-3.5-Turbo.\n",
    "#encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "encoding = tiktoken.get_encoding(\"o200k_base\")\n",
    "# Start a loop to repeatedly prompt the user for a token ID.\n",
    "while True:\n",
    "    print(\"-\" * 40)\n",
    "    user_input = input(\"Enter a token ID (e.g., 24912) to decode, or type 'quit' to exit: \")\n",
    "    \n",
    "    # Check for the exit command.\n",
    "    if user_input.lower() in ['quit', 'exit']:\n",
    "        print(\"Exiting...\")\n",
    "        break\n",
    "    \n",
    "    try:\n",
    "        # Convert the user's input string into an integer.\n",
    "        token_id = int(user_input)\n",
    "        \n",
    "        # Decode the token ID. The `decode` method requires a list of integers.\n",
    "        decoded_text = encoding.decode([token_id])\n",
    "        \n",
    "        # Print the results.\n",
    "        print(f\"\\nToken ID: {token_id}\")\n",
    "        print(f\"Decoded Text: '{decoded_text}'\")\n",
    "        \n",
    "    except ValueError:\n",
    "        # Handle cases where the user enters non-numeric input.\n",
    "        print(\"Invalid input. Please enter a valid number.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed074a0-de70-4893-88bf-022af05f9dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
