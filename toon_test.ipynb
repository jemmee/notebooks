{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7d08511-a9bb-4566-a03f-5591bb7f6b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.12.0-cp313-cp313-manylinux_2_28_aarch64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/ubuntu/anaconda3/lib/python3.13/site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/ubuntu/anaconda3/lib/python3.13/site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/anaconda3/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/anaconda3/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/anaconda3/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (2025.11.12)\n",
      "Downloading tiktoken-0.12.0-cp313-cp313-manylinux_2_28_aarch64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Installing collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58b84d8b-273d-4231-9af9-0449c4250ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== JSON Input ===\n",
      "{\n",
      "  \"users\": [\n",
      "    {\n",
      "      \"id\": 1,\n",
      "      \"name\": \"Alice\",\n",
      "      \"role\": \"admin\",\n",
      "      \"salary\": 75000\n",
      "    },\n",
      "    {\n",
      "      \"id\": 2,\n",
      "      \"name\": \"Bob\",\n",
      "      \"role\": \"user\",\n",
      "      \"salary\": 65000\n",
      "    },\n",
      "    {\n",
      "      \"id\": 3,\n",
      "      \"name\": \"Charlie\",\n",
      "      \"role\": \"user\",\n",
      "      \"salary\": 70000\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "JSON Tokens: 108\n",
      "\n",
      "=== TOON Output ===\n",
      "users[3]{id,name,role,salary}:\n",
      "1,Alice,admin,75000\n",
      "2,Bob,user,65000\n",
      "3,Charlie,user,70000\n",
      "TOON Tokens: 36\n",
      "Savings: 66.7%\n",
      "\n",
      "=== Decoded Back to Dict (Simplified) ===\n",
      "{}\n",
      "\n",
      "=== Non-Uniform Array Demo ===\n",
      "items[2]:\n",
      "  - id: 1\n",
      "  tags: items[1].tags[2]:\n",
      "    - foo\n",
      "    - bar\n",
      "  - id: 2\n",
      "  nested: key: value\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "TOON Demo: Encode/Decode JSON to Token-Oriented Object Notation\n",
    "- Encodes uniform arrays to tabular format\n",
    "- Basic support for objects/arrays/primitives\n",
    "- Token comparison with tiktoken\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import re\n",
    "import tiktoken  # For token counting\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Simple TOON Encoder/Decoder (based on spec from GitHub/toon-format)\n",
    "# ----------------------------------------------------------------------\n",
    "def encode_toon(data, path=\"root\"):\n",
    "    \"\"\"Encode JSON-like data to TOON string.\"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        toon = \"\"\n",
    "        for k, v in data.items():\n",
    "            sub = encode_toon(v, f\"{path}.{k}\")\n",
    "            if sub.strip():\n",
    "                toon += f\"{k}: {sub}\\n\"\n",
    "        return toon.rstrip()\n",
    "    elif isinstance(data, list):\n",
    "        if not data:\n",
    "            return \"[]\"\n",
    "        # Check if uniform array of dicts for tabular\n",
    "        is_uniform = all(isinstance(item, dict) and set(item.keys()) == set(data[0].keys()) for item in data)\n",
    "        if is_uniform and len(data) > 1:\n",
    "            fields = list(data[0].keys())\n",
    "            toon = f\"{path}[{len(data)}]{{{','.join(fields)}}}:\"\n",
    "            for item in data:\n",
    "                row = ','.join(str(item.get(f, '')) for f in fields)\n",
    "                toon += f\"\\n{row}\"\n",
    "            return toon\n",
    "        else:\n",
    "            # Non-uniform: YAML-like list\n",
    "            toon = f\"{path}[{len(data)}]:\"\n",
    "            for i, item in enumerate(data, 1):\n",
    "                sub = encode_toon(item, f\"{path}[{i}]\")\n",
    "                toon += f\"\\n- {sub}\".replace(\"\\n\", \"\\n  \")\n",
    "            return toon\n",
    "    else:\n",
    "        # Primitive\n",
    "        return str(data)\n",
    "\n",
    "def decode_toon(toon_str):\n",
    "    \"\"\"Basic TOON to JSON decoder (simplified; parse headers & rows).\"\"\"\n",
    "    data = {}\n",
    "    lines = toon_str.strip().split('\\n')\n",
    "    stack = [data]\n",
    "    current_key = None\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line or line.startswith('#'):  # Skip comments/empty\n",
    "            continue\n",
    "        if ':' in line and not line.endswith(':'):\n",
    "            # Key: value\n",
    "            key, val = line.split(':', 1)\n",
    "            key = key.strip()\n",
    "            val = val.strip()\n",
    "            if '[' in key:  # Array header\n",
    "                # Parse array, e.g., users[2]{id,name}: \\n1,Alice\\n2,Bob\n",
    "                m = re.match(r'(\\w+)$$ (\\d+) $$\\{([^}]+)\\}:', key)\n",
    "                if m:\n",
    "                    arr_key, size, fields = m.groups()\n",
    "                    arr = []\n",
    "                    for i in range(int(size)):\n",
    "                        row_line = lines[lines.index(line) + 1 + i].strip()\n",
    "                        row_vals = [v.strip() for v in row_line.split(',')]\n",
    "                        item = {f: v for f, v in zip(fields.split(','), row_vals)}\n",
    "                        arr.append(item)\n",
    "                    stack[-1][arr_key] = arr\n",
    "                    continue\n",
    "                # Fallback to list\n",
    "                arr_key, size = re.match(r'(\\w+)$$ (\\d+) $$:', key).groups()\n",
    "                stack[-1][arr_key] = []  # Placeholder; extend for full parse\n",
    "            else:\n",
    "                stack[-1][key] = val\n",
    "        # Indentation for nesting (simplified; assumes 2 spaces)\n",
    "        elif line.startswith('  '):\n",
    "            # Nested under current key\n",
    "            pass  # Extend for full nesting support\n",
    "\n",
    "    return data\n",
    "\n",
    "def count_tokens(text, model=\"gpt-4\"):\n",
    "    \"\"\"Estimate tokens with tiktoken.\"\"\"\n",
    "    enc = tiktoken.encoding_for_model(model)\n",
    "    return len(enc.encode(text))\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Demo Data & Run\n",
    "# ----------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample JSON data (uniform array)\n",
    "    sample_json = {\n",
    "        \"users\": [\n",
    "            {\"id\": 1, \"name\": \"Alice\", \"role\": \"admin\", \"salary\": 75000},\n",
    "            {\"id\": 2, \"name\": \"Bob\", \"role\": \"user\", \"salary\": 65000},\n",
    "            {\"id\": 3, \"name\": \"Charlie\", \"role\": \"user\", \"salary\": 70000}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    json_str = json.dumps(sample_json, indent=2)\n",
    "    print(\"=== JSON Input ===\")\n",
    "    print(json_str)\n",
    "    json_tokens = count_tokens(json_str)\n",
    "    print(f\"JSON Tokens: {json_tokens}\")\n",
    "\n",
    "    # Encode to TOON\n",
    "    toon_str = encode_toon(sample_json[\"users\"], \"users\")\n",
    "    print(\"\\n=== TOON Output ===\")\n",
    "    print(toon_str)\n",
    "    toon_tokens = count_tokens(toon_str)\n",
    "    print(f\"TOON Tokens: {toon_tokens}\")\n",
    "    savings = ((json_tokens - toon_tokens) / json_tokens) * 100\n",
    "    print(f\"Savings: {savings:.1f}%\")\n",
    "\n",
    "    # Decode back to JSON\n",
    "    restored = decode_toon(toon_str)\n",
    "    print(\"\\n=== Decoded Back to Dict (Simplified) ===\")\n",
    "    print(json.dumps(restored, indent=2))\n",
    "\n",
    "    # Test non-uniform\n",
    "    print(\"\\n=== Non-Uniform Array Demo ===\")\n",
    "    non_uniform = [{\"id\": 1, \"tags\": [\"foo\", \"bar\"]}, {\"id\": 2, \"nested\": {\"key\": \"value\"}}]\n",
    "    toon_non = encode_toon(non_uniform, \"items\")\n",
    "    print(toon_non)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2360b4ea-b8b7-4be3-a459-72232c8df13d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
